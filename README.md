# ValuAI - Intelligent Deal Discovery & Pricing Engine

## üìã Project Overview

**ValuAI** is an advanced AI-powered system that automatically discovers, analyzes, and evaluates online bargains by combining multiple machine learning models with intelligent agent coordination. The system identifies potential deals by scraping real-time product listings from RSS feeds, estimates their true market value using an ensemble of pricing models, and alerts users to significant discounts.

### Core Value Proposition
- **Autonomous Deal Detection**: Continuously scans online marketplaces for potential bargains
- **Multi-Model Pricing**: Leverages 3 different pricing approaches (Fine-tuned LLM, LLM with RAG, Deep Neural Network)
- **Intelligent Filtering**: Only alerts users to deals with discount thresholds > $50
- **Persistent Memory**: Maintains historical deals to avoid duplicate notifications
- **Extensible Architecture**: Modular agent-based design for easy customization and scaling

---

## üèóÔ∏è System Architecture

### High-Level Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ValuAI Pipeline Architecture                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  1. INGESTION LAYER                                            ‚îÇ
‚îÇ     ‚îî‚îÄ Deal Scraper (RSS Feeds) ‚Üí Product Descriptions         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  2. PROCESSING LAYER                                           ‚îÇ
‚îÇ     ‚îú‚îÄ Scanner Agent (OpenAI) ‚Üí Validates & Selects Deals      ‚îÇ
‚îÇ     ‚îî‚îÄ Preprocessor ‚Üí Text Normalization (Disabled on Win)     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  3. VALUATION LAYER                                            ‚îÇ
‚îÇ     ‚îú‚îÄ Frontier Agent (GPT with RAG)                           ‚îÇ
‚îÇ     ‚îú‚îÄ Specialist Agent (Fine-tuned Modal Model)               ‚îÇ
‚îÇ     ‚îî‚îÄ Neural Network Agent (Deep NN)                          ‚îÇ
‚îÇ     ‚îî‚îÄ Ensemble Agent (Weighted Combination)                   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  4. DECISION LAYER                                             ‚îÇ
‚îÇ     ‚îú‚îÄ Planning Agent (Orchestration & Filtering)              ‚îÇ
‚îÇ     ‚îî‚îÄ Threshold Check ($50 minimum discount)                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  5. NOTIFICATION LAYER                                         ‚îÇ
‚îÇ     ‚îî‚îÄ Messaging Agent (Pushover Push Notifications)           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  6. PERSISTENCE LAYER                                          ‚îÇ
‚îÇ     ‚îú‚îÄ Chroma Vector Database (Product Embeddings & Metadata)  ‚îÇ
‚îÇ     ‚îî‚îÄ Memory File (memory.json - Deal History)               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ Key Components

### 1. **Deal Scraper & Scanner**
- **File**: `agents/deals.py`, `agents/scanner_agent.py`
- **Function**: Fetches product deals from RSS feeds (DealNews)
- **Sources**: Electronics, Computers, Smart Home products
- **Processing**: 
  - Scrapes 10 items per feed (~30 items per cycle)
  - Extracts HTML snippets and cleans text via BeautifulSoup
  - Calls OpenAI GPT-4o-mini with Structured Outputs to filter best 5 deals
  - Only selects deals with valid prices > $0

**Key Classes**:
- `ScrapedDeal`: Raw scraped deal from RSS
- `Deal`: Validated deal with description, price, URL
- `DealSelection`: Top 5 selected deals from a batch

### 2. **Ensemble Pricing Model**
- **File**: `agents/ensemble_agent.py`
- **Purpose**: Combines three independent pricing models for robust estimates
- **Weighting**:
  - Frontier Agent: **80%** (LLM with context from similar products)
  - Specialist Agent: **10%** (Fine-tuned model on Modal)
  - Neural Network Agent: **10%** (Deep learning model)

**Formula**:
$$\text{Final Price} = 0.8 \times \text{Frontier} + 0.1 \times \text{Specialist} + 0.1 \times \text{NeuralNet}$$

### 3. **Frontier Agent (LLM with RAG)**
- **File**: `agents/frontier_agent.py`
- **Model**: OpenAI GPT-4o-mini
- **Method**: 
  1. Encodes product description using SentenceTransformer (`all-MiniLM-L6-v2`)
  2. Queries Chroma vector database for 5 similar products
  3. Uses similar products as context in the prompt
  4. Sends prompt to OpenAI asking for price estimate
  5. Extracts numerical price from response
- **Advantages**: Context-aware pricing using historical products

### 4. **Specialist Agent (Fine-tuned LLM)**
- **File**: `agents/specialist_agent.py`
- **Model**: Custom fine-tuned model hosted on Modal
- **Architecture**: Remote function calling via Modal serverless
- **Purpose**: Specialized pricing model trained on domain-specific pricing patterns
- **Weight**: 10% (secondary validation)

### 5. **Neural Network Agent**
- **File**: `agents/neural_network_agent.py`, `agents/deep_neural_network.py`
- **Architecture**:
  - **Input Layer**: 5000-dimensional HashingVectorizer features
  - **Residual Blocks**: 10 layers of residual connections
  - **Hidden Size**: 4096 units per layer
  - **Dropout**: 0.2 (regularization)
  - **Output Layer**: Single neuron (price prediction)

**Architecture Details**:
```
Input (5000 dims)
    ‚Üì
[Linear ‚Üí LayerNorm ‚Üí ReLU ‚Üí Dropout]
    ‚Üì
[ResidualBlock] √ó 8 layers
  ‚îî‚îÄ [Linear ‚Üí LayerNorm ‚Üí ReLU ‚Üí Dropout ‚Üí Linear ‚Üí LayerNorm] + skip
    ‚Üì
Output Layer (1 neuron)
    ‚Üì
Denormalization: exp(pred √ó œÉ + Œº) - 1
    (where Œº = 4.435, œÉ = 1.033)
```

**Features**:
- Text hashing vectorization (5000 features, binary encoding)
- Skip connections for gradient flow
- Layer normalization for training stability
- GPU/CPU/MPS device support

### 6. **Planning Agent (Orchestrator)**
- **File**: `agents/planning_agent.py`
- **Role**: Coordinates all other agents
- **Workflow**:
  1. Calls Scanner Agent to get top 5 deals
  2. For each deal, calls Ensemble Agent to estimate true value
  3. Calculates discount: `discount = estimate - deal_price`
  4. Sorts opportunities by discount (highest first)
  5. Checks if best deal exceeds `$50 threshold`
  6. If threshold met, alerts user via Messaging Agent
  7. Returns highest-value opportunity or None

### 7. **Messaging Agent (Notifications)**
- **File**: `agents/messaging_agent.py`
- **Service**: Pushover API for push notifications
- **Features**:
  - Crafts exciting notification messages using Gemini 2.5 Flash
  - Sends formatted alerts with deal details
  - Sound: "cashregister" notification tone

### 8. **Autonomous Planning Agent (Alternative)**
- **File**: `agents/autonomous_planning_agent.py`
- **Purpose**: LLM with tool-use capabilities
- **Tools Provided**:
  - `scan_the_internet_for_bargains()`: Returns deal list
  - `estimate_true_value()`: Estimates product value
  - `notify_user_of_deal()`: Sends user alert
- **Flow**: Agentic loop with OpenAI function calling

---

## üöÄ Quick Start

### Prerequisites

- Python 3.10+
- OpenAI API Key
- Hugging Face Token (for `sentence-transformers`)
- Google AI API Key (for `Gemini`)

### Installation

1. **Clone the repository**
2. **Install dependencies**:
   ```bash
   pip install -r requirements.base.txt -r requirements.ml.txt
   ```
3. **Configure Environment**:
   - Create a `.env` file (see `.env.example`)
   - Add your API keys

### Required Model File

The system requires a pre-trained Neural Network model to operate at full capacity:
- **File**: `deep_neural_network.pth`
- **Placement**: Root directory
- **Note**: The system is designed to degrade gracefully. If this file is missing, the ensemble will proceed using only the Frontier (and Specialist) agents.

### Running the Application

**Direct Execution**:
```bash
python service.py
```

**API Server**:
```bash
uvicorn api:app --reload
```

### Input ‚Üí Processing ‚Üí Output

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COMPLETE DATA FLOW                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

INPUT LAYER:
  ‚Üì
  RSS Feeds (DealNews)
  ‚îú‚îÄ Electronics feed
  ‚îú‚îÄ Computers feed
  ‚îî‚îÄ Smart Home feed
  
  ‚Üì
SCRAPING:
  ‚îî‚îÄ BeautifulSoup extracts: title, description, price, URL, features
  
  ‚Üì
VALIDATION:
  ‚îî‚îÄ Scanner Agent (GPT-4o-mini + Structured Outputs)
     ‚îú‚îÄ Validates price > 0
     ‚îú‚îÄ Checks for "X% off" or "reduced by" (resolves to actual price)
     ‚îú‚îÄ Selects top 5 by description quality
     ‚îî‚îÄ Returns: Deal(description, price, url)
  
  ‚Üì
MEMORY CHECK:
  ‚îî‚îÄ Compares URLs against memory.json
     ‚îî‚îÄ Only processes new deals
  
  ‚Üì
FEATURE EXTRACTION:
  ‚îî‚îÄ Text preprocessing (currently disabled on Windows)
     ‚îî‚îÄ Returns: normalized product description
  
  ‚Üì
VALUATION (3-MODEL ENSEMBLE):

  Model 1: Frontier Agent (80% weight)
  ‚îú‚îÄ Encode description ‚Üí SentenceTransformer vector
  ‚îú‚îÄ Vector search in Chroma DB ‚Üí find 5 similar products
  ‚îú‚îÄ Build context with historical prices
  ‚îú‚îÄ Call GPT-5.1 with context
  ‚îî‚îÄ Extract price ‚Üí Frontier prediction
  
  Model 2: Specialist Agent (10% weight)
  ‚îú‚îÄ Send description to Modal fine-tuned model
  ‚îî‚îÄ Extract price ‚Üí Specialist prediction
  
  Model 3: Neural Network Agent (10% weight)
  ‚îú‚îÄ Hash vectorize description (5000 features)
  ‚îú‚îÄ Forward pass through 10-layer residual network
  ‚îú‚îÄ Denormalize output (exp(z √ó œÉ + Œº) - 1)
  ‚îî‚îÄ Extract price ‚Üí NN prediction
  
  ‚Üì
ENSEMBLE COMBINATION:
  ‚îî‚îÄ Final Price = 0.8√óF + 0.1√óS + 0.1√óN
  
  ‚Üì
OPPORTUNITY IDENTIFICATION:
  ‚îî‚îÄ discount = final_estimate - deal_price
     ‚îú‚îÄ If discount > $50 ‚Üí OPPORTUNITY
     ‚îî‚îÄ If discount ‚â§ $50 ‚Üí DISCARD
  
  ‚Üì
ALERTING:
  ‚îî‚îÄ Messaging Agent
     ‚îú‚îÄ Uses Gemini to craft exciting message
     ‚îú‚îÄ Sends via Pushover API
     ‚îî‚îÄ Message format: "{Sentiment} Price=${price}, Discount=${discount} - {URL}"
  
  ‚Üì
PERSISTENCE:
  ‚îî‚îÄ Memory Update
     ‚îú‚îÄ Appends Opportunity to memory.json
     ‚îî‚îÄ Maintains deal history for deduplication
  
  ‚Üì
OUTPUT:
  ‚îî‚îÄ List[Opportunity]
     ‚îú‚îÄ deal: Deal
     ‚îú‚îÄ estimate: float
     ‚îú‚îÄ discount: float
```

---

## ü§ñ Inference Pipeline (Detailed)

### Single Deal Processing

```python
# Input: Product description (string)
# Output: Opportunity or None

deal_description = "55-inch 4K Smart TV with HDR..."
deal_price = 178.00

# Step 1: Ensemble Agent processes
estimate = ensemble.price(deal_description)
#  ‚îú‚îÄ estimate = (frontier_price √ó 0.8) 
#  ‚îÇ            + (specialist_price √ó 0.1) 
#  ‚îÇ            + (nn_price √ó 0.1)
#  ‚îî‚îÄ Example: estimate = (250 √ó 0.8) + (240 √ó 0.1) + (235 √ó 0.1) = $247.50

# Step 2: Calculate discount
discount = estimate - deal_price  # $247.50 - $178.00 = $69.50

# Step 3: Filter by threshold
if discount > DEAL_THRESHOLD ($50):
    opportunity = Opportunity(
        deal=deal,
        estimate=estimate,
        discount=discount
    )
    # Step 4: Send notification
    messenger.notify(deal_description, deal_price, estimate, url)
    return opportunity
else:
    return None
```

### Model-Specific Inference Details

**Frontier Agent (GPT with RAG)**:
```
description ‚Üí SentenceTransformer encoder ‚Üí 384-dim vector
                  ‚Üì
            Vector DB search (Chroma)
                  ‚Üì
          5 similar products + prices
                  ‚Üì
       Build context prompt
                  ‚Üì
    OpenAI Chat Completion (GPT-5.1)
                  ‚Üì
    Extract price from response
```

**Neural Network Agent**:
```
description ‚Üí HashingVectorizer (5000 features, binary)
                  ‚Üì
         Convert to PyTorch tensor
                  ‚Üì
    Forward pass through 10 layers:
    ‚îú‚îÄ Input layer: Linear(5000‚Üí4096) + LayerNorm + ReLU + Dropout
    ‚îú‚îÄ 8√ó Residual blocks (same hidden size)
    ‚îî‚îÄ Output layer: Linear(4096‚Üí1)
                  ‚Üì
     Denormalize: exp(output √ó 1.033 + 4.435) - 1
                  ‚Üì
    Return max(0, price_estimate)
```

---

## üóÑÔ∏è Data Persistence

### Chroma Vector Database
- **Path**: `products_vectorstore/`
- **Collection**: "products"
- **Stored Data**:
  - **embeddings**: 384-dim vectors (from SentenceTransformer)
  - **documents**: Product descriptions
  - **metadatas**: `{"price": float, "category": str}`

### Memory File
- **Path**: `memory.json`
- **Format**: JSON array of Opportunity objects
- **Purpose**: 
  - Prevent duplicate deal notifications
  - Maintain historical deal data
  - Enable URL-based deduplication

**Structure**:
```json
[
  {
    "deal": {
      "product_description": "...",
      "price": 178.0,
      "url": "..."
    },
    "estimate": 247.5,
    "discount": 69.5
  }
]
```

---

## üöÄ Execution Flow

### Entry Points

#### 1. **Service Entrypoint** (`service.py`)
```python
def run_pricer_cycle() -> List[Opportunity]:
    framework = get_agent_framework()
    opportunities = framework.run()
    return opportunities
```

#### 2. **API Entrypoint** (`api.py`)
```python
@app.post("/run", response_model=List[Opportunity])
def run_agents():
    return run_pricer_cycle()
```

#### 3. **Direct Execution**
```bash
python deal_agent_framework.py
```

### Execution Steps

1. **Initialization**
   - Load `.env` for API keys
   - Initialize Chroma client
   - Read memory.json
   - Setup Planning Agent with Chroma collection

2. **Deal Scanning**
   - ScannerAgent fetches from RSS feeds
   - BeautifulSoup extracts product data
   - OpenAI validates and selects top 5
   - Filters out URLs already in memory

3. **Pricing & Evaluation**
   - EnsembleAgent processes each deal
   - 3 models run in parallel (conceptually)
   - Weighted combination produces final estimate
   - Discount calculated

4. **Filtering & Alerting**
   - PlanningAgent checks $50 threshold
   - Best deal selected (highest discount)
   - MessagingAgent sends notification if qualified
   - Opportunity appended to memory

5. **Persistence**
   - memory.json updated with new opportunities
   - Chroma vectors indexed

---

## üìö Models & Algorithms

### Model Summary

| Agent | Model | Input | Output | Weight |
|-------|-------|-------|--------|--------|
| **Frontier** | GPT-5.1 | Description + Similar products | Price estimate | 80% |
| **Specialist** | Fine-tuned Modal | Description | Price estimate | 10% |
| **Neural Net** | ResidualNet (10 layers) | 5000-dim features | Price estimate | 10% |

### Feature Engineering

**Neural Network Features**:
- HashingVectorizer: Binary term frequency
- Dimensions: 5000
- Stop words: English
- Purpose: Fast, deterministic feature extraction

**Frontier Agent Embeddings**:
- Model: `sentence-transformers/all-MiniLM-L6-v2`
- Dimensions: 384
- Purpose: Semantic similarity for RAG

---

## üîß Configuration

### Environment Variables (`.env`)

```env
# LLM Providers
OPENAI_API_KEY=sk-...
HF_TOKEN=hf_...
GEMINI_API_KEY=AIzaSy...

# Notifications
PUSHOVER_USER=...
PUSHOVER_TOKEN=...

# Runtime
ENV=production
```

### Thresholds & Hyperparameters

| Parameter | Value | File |
|-----------|-------|------|
| Deal Threshold | $50 | `planning_agent.py` |
| Ensemble Weights | [0.8, 0.1, 0.1] | `ensemble_agent.py` |
| NN Hidden Size | 4096 | `deep_neural_network.py` |
| NN Layers | 10 | `deep_neural_network.py` |
| NN Dropout | 0.2 | `deep_neural_network.py` |
| Vector DB Results | 5 | `frontier_agent.py` |
| Scanner Deals | 5 | `scanner_agent.py` |

---

## üì¶ Dependencies

### Core Stack
- **FastAPI**: REST API framework
- **PyTorch**: Deep learning
- **Transformers**: Hugging Face models
- **SentenceTransformers**: Semantic embeddings
- **Chroma**: Vector database
- **OpenAI**: GPT API
- **LiteLLM**: LLM abstraction layer
- **BeautifulSoup4**: HTML parsing
- **Feedparser**: RSS parsing

### Detailed Dependencies
See `requirements.base.txt`, `requirements.ml.txt`, `requirements.docker.txt`

---

## üê≥ Deployment

### Docker Containerization

**Build**:
```bash
docker build -t valuai:latest .
```

**Run**:
```bash
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=$OPENAI_API_KEY \
  -e HF_TOKEN=$HF_TOKEN \
  valuai:latest
```

**Healthcheck**:
```
GET /health ‚Üí {"status": "ok"}
```

---

## üß™ Testing & Evaluation

### Evaluator Module (`agents/evaluator.py`)

Provides comprehensive performance metrics:
- **Mean Absolute Error (MAE)**: Average prediction error in dollars
- **Mean Squared Error (MSE)**: Penalizes large errors
- **R¬≤ Score**: Variance explained by model (0-100%)
- **Error Trends**: Running average error with 95% confidence intervals

**Usage**:
```python
from agents.evaluator import evaluate
evaluate(predictor_function, test_data, size=200)
```

---

## üîÑ Workflow Summary

### Daily/Hourly Cycle

1. **Scan** ‚Üí Fetch top 5 new deals from RSS
2. **Validate** ‚Üí Use OpenAI to filter by quality
3. **Price** ‚Üí Ensemble of 3 models estimates true value
4. **Compare** ‚Üí Check if discount exceeds $50 threshold
5. **Alert** ‚Üí Send push notification to user
6. **Remember** ‚Üí Store opportunity in memory

### Benefits

‚úÖ **Automated**: Runs continuously without manual intervention
‚úÖ **Ensemble**: Combines multiple models for robustness
‚úÖ **Fast**: Parallel potential (with async improvements)
‚úÖ **Scalable**: Vector DB enables efficient similarity search
‚úÖ **Intelligent**: Uses LLMs for semantic understanding
‚úÖ **Persistent**: Never shows same deal twice

---

## üõ†Ô∏è Future Enhancements

- Async model execution for parallel pricing
- Fine-tuning ensemble weights based on historical accuracy
- Expand RSS feed sources
- Category-specific pricing models
- Web scraping beyond RSS feeds
- ML model explainability (SHAP values)
- A/B testing notification strategies
- User preference learning

---

## üìû Support

For issues or questions, refer to:
- `.env.example` for configuration
- Individual agent docstrings for implementation details
- `deep_neural_network.py` for model architecture

---

**ValuAI** ¬© 2026 | AI-Powered Deal Discovery Engine
